{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeoyujie/cmpsc448/blob/main/CMPSC448.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_8XVvjE2ua5"
      },
      "source": [
        "# **1. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfu7wu4P15Bs"
      },
      "source": [
        "### Import all the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSfl_-CN18nJ"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjngEXRpe7Po",
        "outputId": "3c7d6bb1-1b29-4b4b-d996-84131cf9cbd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  train.txt.gz  unlabeled_test_test.txt\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3-N5RhK2MMs"
      },
      "source": [
        "### Load the data file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44a5aBLn2G6S"
      },
      "outputs": [],
      "source": [
        "# Unzipping the file\n",
        "with gzip.open('train.txt.gz', 'rt') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Splitting the data into lines\n",
        "lines = data.split('\\n')\n",
        "\n",
        "# Splitting each line into its components and removing lines that are empty\n",
        "lines = [line.split() for line in lines if line]\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(lines, columns=['Token', 'POS tag', 'Chunking tag'])\n",
        "\n",
        "# Dropping the 'Chunking tag' column as it's not needed for this project\n",
        "df = df.drop('Chunking tag', axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tovu3sXFInoO"
      },
      "source": [
        " #### Check for missing and duplicate values.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48-N82JIIJmj",
        "outputId": "f746c0e6-3ab7-440c-e3ac-24d4198bf9a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token      0\n",
            "POS tag    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# If there are missing values in 'Token' or 'POS tag' columns, we drop those rows\n",
        "df = df.dropna(subset=['Token', 'POS tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkMJ4AAyTFm-",
        "outputId": "bf5f5f01-98e5-430c-dda7-3101b1ac233d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Token POS tag\n",
            "0       Confidence      NN\n",
            "1               in      IN\n",
            "2              the      DT\n",
            "3            pound      NN\n",
            "4               is     VBZ\n",
            "...            ...     ...\n",
            "211688       2,480      CD\n",
            "211689        cots     NNS\n",
            "211696       pints     NNS\n",
            "211698      Type-O      JJ\n",
            "211715    Huricane     NNP\n",
            "\n",
            "[20939 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "## For checking, remove later\n",
        "print(df)\n",
        "df.to_csv('df.txt', index=False, sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqdhQcaWUh4q"
      },
      "source": [
        "## 2. Split the data and vectorisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5SkBPEKo7yk"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(df['Token'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z157QyRXpBsp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['POS tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLDwWg2VUhPz"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfBlI_ODQGAl"
      },
      "source": [
        "# **3. Model Training**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1joHA5txQOR1"
      },
      "source": [
        "## Bayesian Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP39KISKvCiK",
        "outputId": "b11164fe-6ff1-4548-ac2b-49b46d313583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:  [0.27364966 0.28119403 0.2841791  0.28925373 0.28358209]\n",
            "Mean cross-validation score:  0.28237172240854813\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         5\n",
            "           9       0.96      0.66      0.79       378\n",
            "          10       0.00      0.00      0.00         6\n",
            "          12       0.00      0.00      0.00         4\n",
            "          13       0.00      0.00      0.00        28\n",
            "          14       0.46      0.28      0.35       572\n",
            "          15       0.00      0.00      0.00        10\n",
            "          16       0.00      0.00      0.00        11\n",
            "          17       0.00      0.00      0.00         3\n",
            "          18       0.25      0.12      0.16       761\n",
            "          19       0.22      0.81      0.35       864\n",
            "          20       0.00      0.00      0.00        26\n",
            "          21       0.59      0.13      0.22       408\n",
            "          24       0.00      0.00      0.00         5\n",
            "          25       0.00      0.00      0.00         3\n",
            "          26       0.00      0.00      0.00       131\n",
            "          27       0.00      0.00      0.00         2\n",
            "          29       0.00      0.00      0.00         1\n",
            "          31       0.00      0.00      0.00         1\n",
            "          32       0.00      0.00      0.00         4\n",
            "          33       0.00      0.00      0.00       215\n",
            "          34       0.00      0.00      0.00       173\n",
            "          35       0.00      0.00      0.00       186\n",
            "          36       0.00      0.00      0.00       200\n",
            "          37       0.00      0.00      0.00        84\n",
            "          38       0.00      0.00      0.00        98\n",
            "          39       0.00      0.00      0.00         2\n",
            "          40       0.00      0.00      0.00         3\n",
            "          42       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.30      4188\n",
            "   macro avg       0.08      0.06      0.06      4188\n",
            "weighted avg       0.30      0.30      0.24      4188\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Multinomial Naive Bayes classifier\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# Perform 5-fold cross validation\n",
        "scores = cross_val_score(nb, X_train, y_train, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores: \", scores)\n",
        "print(\"Mean cross-validation score: \", scores.mean())\n",
        "\n",
        "# Fit the model to the training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the validation set\n",
        "y_val_pred = nb.predict(X_val)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiBX8flhx0jl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJDXoAamQQgK"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNYgJJh1tco0",
        "outputId": "44248284-252d-49e7-b812-29cce5485fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.metrics import accuracy_score\n",
        "# Initialize the model\n",
        "#model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "#model.fit(X_train_tfidf, y_train)\n",
        "#y_val_pred_lin = lin.predict(X_train_tfidf[:2, :])\n",
        "#accuracy = accuracy_score(y_val, y_val_pred_lin)\n",
        "\n",
        "# Train the Logistic model with maximum iteration of 1000\n",
        "#lin = LogisticRegression(max_iter=2000, C=0.001).fit(X_train_tfidf, y_train)\n",
        "\n",
        "\n",
        "#y_val_pred_lin = lin.predict(X_val_tfidf)\n",
        "\n",
        "\n",
        "\n",
        "#print(classification_report(y_val, y_val_pred_lin))\n",
        "\n",
        "#new\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Define the model\n",
        "model = LogisticRegression(max_iter = 1000)\n",
        "\n",
        "# Define the parameters to tune\n",
        "param_dist = {\n",
        "    'C': uniform(0.001, 1000),  # Randomly sample C from a uniform distribution\n",
        "    'max_iter': randint(1000, 2000)  # Randomly sample max_iter from a uniform distribution\n",
        "}\n",
        "\n",
        "# Initialize a RandomizedSearchCV object that will perform the hyperparameter tuning\n",
        "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=5, cv=3,)\n",
        "\n",
        "# Use a smaller dataset for hyperparameter tuning\n",
        "#X_train_tfidf_small = X_train[:1000]  # Example: Use the first 1000 samples\n",
        "\n",
        "# Fit the data to perform hyperparameter tuning with a smaller dataset\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Fit the data to perform hyperparameter tuning\n",
        "#random_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters: \", random_search.best_params_)\n",
        "\n",
        "# Use the best model to make predictions\n",
        "best_model = random_search.best_estimator_\n",
        "y_val_pred_lin = best_model.predict(X_val)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_val, y_val_pred_lin))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-oXfdOHQUEj"
      },
      "source": [
        "## Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9QjZJlgluHK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "14aabb20-046e-4aac-e2c7-d6dc2d01157a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b769a2a920e1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvm_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Training the SVM on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msvm_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
          ]
        }
      ],
      "source": [
        "# Model Initialization\n",
        "svm_classifier = SVC(kernel='linear', probability=True, random_state=42)\n",
        "\n",
        "# Training the SVM on the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the trained SVM on the validation data\n",
        "# Predict the labels of the validation set\n",
        "y_val_pred_svm = svm_classifier.predict(X_val)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(classification_report(y_val, y_val_pred_svm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "GlqskJWcsee8",
        "outputId": "b68ca19a-df5a-4437-e82f-60072010ae2e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1a03a3b865d2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define the parameters to tune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
          ]
        }
      ],
      "source": [
        "## Better SVM with grid search optimisation\n",
        "\n",
        "# Define the model\n",
        "model = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Define the parameters to tune\n",
        "parameters = {'C': [0.1, 1, 10],\n",
        "              'kernel': ['linear', 'rbf'],\n",
        "              'gamma': [0.1, 1, 10]}\n",
        "\n",
        "# Initialize a GridSearchCV object that will perform the hyperparameter tuning\n",
        "grid_search = GridSearchCV(model, parameters, cv=5)\n",
        "\n",
        "# Fit the data to perform hyperparameter tuning\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "\n",
        "# Use the best model to make predictions\n",
        "best_model = grid_search.best_estimator_\n",
        "y_val_pred_svm2 = best_model.predict(X_val)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_val, y_val_pred_svm2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGb_SvVQUPTJ"
      },
      "source": [
        "## 4. Model Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsXF1O24HA04"
      },
      "source": [
        "### Imported unlabeled test file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MyNOSav-EKQ"
      },
      "outputs": [],
      "source": [
        "df_unlabeled = pd.read_csv('unlabeled_test_test.txt', header=None, names=['Token'], sep='\\t', error_bad_lines=False, quoting=3, skip_blank_lines=False)\n",
        "\n",
        "# Display the first few rows\n",
        "print(df_unlabeled.head())\n",
        "\n",
        "\n",
        "# Replace NaN values with an empty string\n",
        "df_unlabeled['Token'].fillna(\"\", inplace=True)\n",
        "\n",
        "\n",
        "num_rows = df_unlabeled.shape[0]\n",
        "print(\"Number of rows: \", num_rows)\n",
        "\n",
        "output_file_path = 'output.txt'\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "df_unlabeled.to_csv(output_file_path, index=False, header=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJhDAkDwxfWb"
      },
      "outputs": [],
      "source": [
        "# Transform the unlabeled data using the same vectorizer\n",
        "X_unlabeled = tfidf_vectorizer.transform(df_unlabeled['Token'])\n",
        "\n",
        "# Predict the POS tags of the unlabeled data\n",
        "y_unlabeled_pred = nb.predict(X_unlabeled)\n",
        "\n",
        "# Convert the predicted labels back to their original form\n",
        "y_unlabeled_pred_tags = label_encoder.inverse_transform(y_unlabeled_pred)\n",
        "\n",
        "# Create a DataFrame with the tokens and their predicted POS tags\n",
        "df_test = pd.DataFrame({'Token': df_unlabeled['Token'], 'Predicted POS tag': y_unlabeled_pred_tags})\n",
        "\n",
        "# Save the DataFrame to a text file\n",
        "df_test.to_csv('teamname.test.txt', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVUUw4w7xkq1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7YN2YpYUTqU"
      },
      "source": [
        "## 5. Results Interpretation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}